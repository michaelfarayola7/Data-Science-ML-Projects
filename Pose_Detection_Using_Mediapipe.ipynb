{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelfarayola7/Data-Science-ML-Projects/blob/main/Pose_Detection_Using_Mediapipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JJQeFVnBYM_"
      },
      "outputs": [],
      "source": [
        "#For this propject, you need to install mediapipe\n",
        "\n",
        "#!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSfwwPkJBPTy",
        "outputId": "09eb847f-5ac6-4361-e253-23ffc334a524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9NXUR7SBdUE"
      },
      "outputs": [],
      "source": [
        "#Capturing and visualizing the various pose videos\n",
        "\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture('1.mp4')\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # Resize the image\n",
        "    resized_img = cv2.resize(img, (800, 700))  # Specify the new dimensions\n",
        "\n",
        "    # Display the resized image\n",
        "    cv2.imshow('posedection', resized_img)\n",
        "\n",
        "    # Break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STL_5XjLC5u1"
      },
      "outputs": [],
      "source": [
        "\n",
        "mPose = mp.solutions.pose\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "pose = mPose.Pose()\n",
        "\n",
        "cap = cv2.VideoCapture('1.mp4')\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # Resize the image\n",
        "    resized_img = cv2.resize(img, (800, 700))  # Specify the new dimensions\n",
        "\n",
        "    #Using Pose to process the image\n",
        "    result = pose.process(resized_img)\n",
        "    mpDraw.draw_landmarks(resized_img, result.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)\n",
        "\n",
        "    # Display the resized image\n",
        "    cv2.imshow('posedection', resized_img)\n",
        "\n",
        "    # Break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2N594gZ7uxs"
      },
      "source": [
        "## Pose Detection and Extraction of Detected Pose on Blank Canvas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3v9R7O77uxt"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "# Initialize MediaPipe Pose and Drawing Utils\n",
        "mPose = mp.solutions.pose\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "pose = mPose.Pose()\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture('3.mp4')\n",
        "\n",
        "#Changing the colour of the connections\n",
        "drawspec1 = mpDraw.DrawingSpec(thickness = 2, circle_radius = 3, color = (0,0,255))\n",
        "drawspec2 = mpDraw.DrawingSpec(thickness = 2, circle_radius = 3, color = (0,255,0))\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # Resize the image\n",
        "    resized_img = cv2.resize(img, (800, 700))  # Specify the new dimensions\n",
        "\n",
        "    # Using Pose to process the resized image\n",
        "    result = pose.process(resized_img)\n",
        "\n",
        "    # Draw landmarks on the resized image\n",
        "    if result.pose_landmarks:  # Check if any landmarks are detected\n",
        "        mpDraw.draw_landmarks(resized_img, result.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS, drawspec1, drawspec2)\n",
        "\n",
        "    #Extracting the pose on a blank canvas by creating a blank image canvas\n",
        "    h, w, c  = resized_img.shape\n",
        "    img_Blank = np.zeros([h, w, c])\n",
        "    img_Blank.fill(255)\n",
        "    mpDraw.draw_landmarks(img_Blank, result.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS, drawspec1, drawspec2)\n",
        "\n",
        "    # Display the resized image with landmarks\n",
        "    cv2.imshow('Pose Detection', resized_img)\n",
        "    cv2.imshow('ExtractedPose', img_Blank)\n",
        "\n",
        "    # Break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Cleanup\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sViHij77uxu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}