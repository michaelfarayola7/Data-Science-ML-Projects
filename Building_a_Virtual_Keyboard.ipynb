{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelfarayola7/Data-Science-ML-Projects/blob/main/Building_a_Virtual_Keyboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "959f40f0",
      "metadata": {
        "id": "959f40f0"
      },
      "source": [
        "## Using/Displaying your camera"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cc93eb2",
      "metadata": {
        "id": "8cc93eb2"
      },
      "source": [
        "#### Libraries to Install\n",
        "* cv2\n",
        "* cvzone\n",
        "* mediapipe\n",
        "* pyautogui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67db7a93",
      "metadata": {
        "id": "67db7a93"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Open the default camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Read a new frame from the camera\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # Display the frame in a window named 'camera'\n",
        "    cv2.imshow('camera', img)\n",
        "\n",
        "    # Break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the camera and close all OpenCV windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dad89468",
      "metadata": {
        "id": "dad89468"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from time import sleep\n",
        "import pyautogui as keyboard\n",
        "\n",
        "# Open the default camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Set the dimensions of the camera frame\n",
        "cap.set(3, 1280)\n",
        "cap.set(4, 720)\n",
        "\n",
        "keys = [[\"Q\", \"W\", \"E\", \"R\", \"T\", \"Y\", \"U\", \"I\", \"O\", \"P\"],\n",
        "        [\"A\", \"S\", \"D\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \";\"],\n",
        "        [\"Z\", \"X\", \"C\", \"V\", \"B\", \"N\", \"M\", \",\", \".\", \"/\"]]\n",
        "\n",
        "class Button():\n",
        "    def __init__(self, pos, text, size=[80,80]):\n",
        "        self.pos = pos\n",
        "        self.text = text\n",
        "        self.size = size\n",
        "        self.color = (0, 0, 0)  # Initial color\n",
        "\n",
        "    def draw(self, img):\n",
        "        x, y = self.pos\n",
        "        w, h = self.size\n",
        "\n",
        "        # Draw the rectangle and text on the image with current color\n",
        "        cv2.rectangle(img, self.pos, (x+w, y+h), self.color, cv2.FILLED)\n",
        "        cv2.putText(img, self.text, (x+20, y+65), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
        "        return img\n",
        "\n",
        "    def set_color(self, color):\n",
        "        self.color = color\n",
        "\n",
        "# Initialize mediapipe hands\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands()\n",
        "\n",
        "buttonList = []\n",
        "\n",
        "for i in range(len(keys)):\n",
        "    for j, key in enumerate(keys[i]):\n",
        "        buttonList.append(Button([100 * j+50, 100 * i+100], key))\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Read a new frame from the camera\n",
        "    success, img = cap.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # Convert the image to RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Detect hands in the image\n",
        "    results = hands.process(img_rgb)\n",
        "\n",
        "    # Draw landmarks and connections on the image if hands are detected\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            # Draw landmark points\n",
        "            for lm in hand_landmarks.landmark:\n",
        "                h, w, c = img.shape\n",
        "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
        "\n",
        "            # Draw connections between landmarks\n",
        "            connections = mp_hands.HAND_CONNECTIONS\n",
        "            for connection in connections:\n",
        "                point1 = connection[0]\n",
        "                point2 = connection[1]\n",
        "                x1, y1 = int(hand_landmarks.landmark[point1].x * w), int(hand_landmarks.landmark[point1].y * h)\n",
        "                x2, y2 = int(hand_landmarks.landmark[point2].x * w), int(hand_landmarks.landmark[point2].y * h)\n",
        "                cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
        "\n",
        "\n",
        "    # Simulate key presses when hand hovers over buttons\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            for lm in hand_landmarks.landmark:\n",
        "                h, w, c = img.shape\n",
        "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                for button in buttonList:\n",
        "                    x, y = button.pos\n",
        "                    w, h = button.size\n",
        "                    if x < cx < x+w and y < cy < y+h:\n",
        "                        cv2.rectangle(img, button.pos, (x+w, y+h), (255, 0, 0), cv2.FILLED)\n",
        "                        cv2.putText(img, button.text, (x+20, y+65), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
        "                        distance = ((lm.x - (x + w / 2)) ** 2 + (lm.y - (y + h / 2)) ** 2) ** 0.5\n",
        "                        if distance < w / 2:\n",
        "                            button.set_color((0, 255, 0))  # Change color to green\n",
        "                            keyboard.press(button.text)\n",
        "                            sleep(0.2)\n",
        "                        else:\n",
        "                            button.set_color((0, 0, 0))  # Change color back to black\n",
        "\n",
        "    # Draw all buttons on the image\n",
        "    for button in buttonList:\n",
        "        img = button.draw(img)\n",
        "\n",
        "    # Display the frame in a window named 'camera'\n",
        "    cv2.imshow('camera', img)\n",
        "\n",
        "    # Break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the camera and close all OpenCV windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c303658",
      "metadata": {
        "id": "4c303658"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "from time import sleep\n",
        "from pynput.keyboard import Controller\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3,1280)\n",
        "cap.set(4,720)\n",
        "detector = HandDetector(detectionCon=0.8)\n",
        "\n",
        "keys = [[\"Q\", \"W\", \"E\", \"R\", \"T\", \"Y\", \"U\", \"I\", \"O\", \"P\"],\n",
        "        [\"A\", \"S\", \"D\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \";\"],\n",
        "        [\"Z\", \"X\", \"C\", \"V\", \"B\", \"N\", \"M\", \",\", \".\", \"/\"]]\n",
        "\n",
        "ClickedText = \"\"\n",
        "keyboard = Controller()\n",
        "def drawALL(img,buttonList):\n",
        "\n",
        "    for button in buttonList:\n",
        "        x, y = button.pos\n",
        "        w, h = button.size\n",
        "        cv2.rectangle(img, button.pos, (x + w, y + h), (255, 0, 255), cv2.FILLED)\n",
        "        cv2.putText(img, button.text, (x + 20, y + 65), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
        "    return img\n",
        "\n",
        "\n",
        "class Button():\n",
        "    def __init__(self,pos,text,size=[80,80]):\n",
        "        self.pos = pos\n",
        "        self.text = text\n",
        "        self.size = size\n",
        "\n",
        "\n",
        "# myButton = Button([100,100],'Q')\n",
        "# myButton1 = Button([200,100],'W')\n",
        "# myButton2 = Button([300,100],'E')\n",
        "# myButton3 = Button([400,100],'R')\n",
        "buttonList = []\n",
        "for i in range(len(keys)):\n",
        "    for j, key in enumerate(keys[i]):\n",
        "        buttonList.append(Button([100 * j + 50, 100 * i + 50], key))\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    img= detector.findHands(img)\n",
        "    lmlist, bboxInfo = detector.findPosition(img)\n",
        "    drawALL(img, buttonList)\n",
        "\n",
        "    if lmlist:\n",
        "        for button in buttonList:\n",
        "            x,y = button.pos\n",
        "            w,h = button.size\n",
        "            if x<lmlist[8][0]<x+w and y<lmlist[8][1] < y+h:\n",
        "                cv2.rectangle(img, button.pos, (x + w, y + h), (255, 0, 0), cv2.FILLED)\n",
        "                cv2.putText(img, button.text, (x + 20, y + 65), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
        "                l,_,_=detector.findDistance(8,12,img)\n",
        "                # print(l)\n",
        "                if l < 50:\n",
        "                    keyboard.press(button.text)\n",
        "                    cv2.rectangle(img, button.pos, (x + w, y + h), (0, 255, 0), cv2.FILLED)\n",
        "                    cv2.putText(img, button.text, (x + 20, y + 65), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
        "                    ClickedText += button.text\n",
        "                    sleep(0.2)\n",
        "    cv2.rectangle(img, (55,345), (700,450), (255, 0, 0), cv2.FILLED)\n",
        "    cv2.putText(img, ClickedText, (60,425), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
        "\n",
        "    # cv2.rectangle(img,(100,100),(200,200),(0,0,0),cv2.FILLED)\n",
        "    # cv2.putText(img,'Q',(120,180),cv2.FONT_HERSHEY_SIMPLEX,3,(255,255,255),5)\n",
        "    # myButton = Button([100,100],'Q')\n",
        "\n",
        "    # img = myButton1.draw(img)\n",
        "    # img = myButton2.draw(img)\n",
        "    # img = myButton3.draw(img)\n",
        "    cv2.imshow('camera',img)\n",
        "    cv2.waitKey(1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}